---
---
@article{ren2024grounding,
      title={Grounding DINO 1.5: Advance the "Edge" of Open-Set Object Detection}, 
      author={Tianhe Ren* and Qing Jiang* and Shilong Liu* and Zhaoyang Zeng* and Wenlong Liu and Han Gao and Hongjie Huang and Zhengyu Ma and Xiaoke Jiang and Yihao Chen and Yuda Xiong and Hao Zhang and Feng Li and Peijun Tang and Kent Yu and Lei Zhang},
      year={2024},
      journal={arXiv:2405.10300},
      eprint={2405.10300},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      html={https://deepdataspace.com/},
      summary={Grounding DINO 1.5 Pro â€” our most capable model for open-set object detection.},
      selected={true},
      preview={gd15.gif},
      bibtex_show={true},
}

@article{liu2023grounding,
  title={LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents},
  author={Liu, Shilong and Cheng, Hao and Liu, Haotian and Zhang, Hao and Li, Feng and Ren, Tianhe and Zou, Xueyan and Yang, Jianwei and Su, Hang and Zhu, Jun and Zhang, Lei and Gao, Jianfeng and Li, Chunyuan},
  journal={To be shown in ECCV},
  year={2024},
  selected={true},
  preview={llava-plus-pv.png},
  summary={Equip multimodal large language models with tools to create multimodal agents.},
  bibtex_show={true},
  code={https://github.com/LLaVA-VL/LLaVA-Plus-Codebase},
  codebadge={https://img.shields.io/github/stars/LLaVA-VL/LLaVA-Plus-Codebase},
  html={https://llava-vl.github.io/llava-plus/},
}

@article{liu2023grounding,
  title={Grounding {DINO}: Marrying dino with grounded pre-training for open-set object detection},
  author={Liu, Shilong and Zeng, Zhaoyang and Ren, Tianhe and Li, Feng and Zhang, Hao and Yang, Jie and Li, Chunyuan and Yang, Jianwei and Su, Hang and Zhu, Jun and others},
  journal={To be shown in ECCV},
  year={2023},
  selected={true},
  preview={groundingdino_pv.png},
  summary={SOTA open-set object detector. 52.5AP on COCO without COCO training data!},
  bibtex_show={true},
  code={https://github.com/IDEA-Research/GroundingDINO},
  codebadge={https://img.shields.io/github/stars/IDEA-Research/GroundingDINO,https://img.shields.io/github/stars/IDEA-Research/Grounded-Segment-Anything},
}

@inproceedings{FengLi2023MaskDT,
  title={Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation},
  author={Feng Li and Hao Zhang and Huaizhe Xu and Shilong Liu and Lei Zhang and Lionel M Ni and Heung-Yeung Shum},
  year={2023},
  preview={maskdino_pv.jpeg},
  summary={SOTA object detection and segmentation model.},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  bibtex_show={true},
  arxiv={2206.02777},
  code={https://github.com/IDEA-Research/MaskDINO},
}

@inproceedings{dqdetr,
  title={{DQ-DETR}: Dual Query Detection Transformer for Phrase Extraction and Grounding},
  author={Shilong, Liu and Yaoyuan, Liang and Shijia, Huang and Feng, Li and Hao, Zhang and Hang, Su and Jun, Zhu and Lei, Zhang},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  journal={AAAI},
  year={2023},
  preview={dqdetr_pv.png},
  summary={A comparison of object detection, REC, and phrase grounding tasks.},
  bibtex_show={true},
  arxiv={2211.15516},
  code={https://github.com/IDEA-Research/DQ-DETR},
}

@inproceedings{zhang2022dino,
      title={DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection}, 
      author={Hao Zhang* and Feng Li* and Shilong Liu* and Lei Zhang and Hang Su and Jun Zhu and Lionel M. Ni and Heung-Yeung Shum},
      booktitle={International Conference on Learning Representations},
      year={2023},
      selected={true},
      preview={dino_pv.png},
  summary={The first DETR-based object detector that achieved 1st on the COCO detection leaderboard.},
  bibtex_show={true},
  arxiv={2203.03605},
  code={https://github.com/IDEACVR/DINO},
  codebadge={https://img.shields.io/github/stars/IDEA-Research/DINO},
}

@inproceedings{li2022dn,
      title={DN-DETR: Accelerate detr training by introducing query denoising},
      author={Li*, Feng and Zhang*, Hao and Liu, Shilong and Guo, Jian and Ni, Lionel M and Zhang, Lei},
      booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
      pages={13619--13627},
      year={2022},
      preview={dndetr_pv.png},
  summary={A novel denoising training strategy for DETR, achieving faster convergence and better performance.},
  bibtex_show={true},
  arxiv={2203.01305},
  code={https://github.com/IDEA-Research/DN-DETR},
}

@inproceedings{
      liu2022dabdetr,
      title={{DAB}-{DETR}: Dynamic Anchor Boxes are Better Queries for {DETR}},
      author={Shilong Liu and Feng Li and Hao Zhang and Xiao Yang and Xianbiao Qi and Hang Su and Jun Zhu and Lei Zhang},
      booktitle={International Conference on Learning Representations},
      year={2022},
      url={https://openreview.net/forum?id=oMI9PjOb9Jl},
      selected={true},
      preview={dabdetr_pv.png},
      summary={A deep understanding of DETR's query, and formulating queries as anchor boxes.},
  bibtex_show={true},
  arxiv={2201.12329},
  code={https://github.com/IDEA-Research/DAB-DETR},
  codebadge={https://img.shields.io/github/stars/IDEA-Research/DAB-DETR},
}

@article{liu2021query2label,
      title={Query2Label: A Simple Transformer Way to Multi-Label Classification}, 
      author={Shilong Liu and Lei Zhang and Xiao Yang and Hang Su and Jun Zhu},
      year={2021},
      journal={arXiv:2107.10834},
      eprint={2107.10834},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      selected={true},
      summary={A novel transformer-based multi-label classification model, achieving SOTA on four benchmarks.},
      preview={q2l_pv.png},
  bibtex_show={true},
  arxiv={2107.10834},
  code={https://github.com/SlongLiu/query2labels},
  codebadge={https://img.shields.io/github/stars/SlongLiu/query2labels},
}