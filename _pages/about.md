---
layout: about
title: about
permalink: /
# subtitle: PhD Candidate at <a href='https://www.tsinghua.edu.cn/en/'>Tsinghua University</a>. 

profile:
  align: right
  image: me.jpg
  image_circular: false # crops the image to make it circular
  # more_info: >
  #   <p>555 your office number</p>
  #   <p>123 your address street</p>
  #   <p>Your City, State 12345</p>

news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---
Hi! This is Shilong Liu (刘世隆). I'm a `ceil(now() - 2020.9)`th year Ph.D. candidate at the [Department of Computer Science and Technology](http://www.cs.tsinghua.edu.cn/publish/csen/index.html), [Tsinghua University](https://www.tsinghua.edu.cn/en/), under the supervision of Prof. [Lei Zhang](https://www.leizhang.org/), Prof. [Hang Su](https://www.suhangss.me/), and Prof. [Jun Zhu](https://ml.cs.tsinghua.edu.cn/~jun/index.shtml). I got my bachelor's degree from the [Department of Industrial Engineering](http://www.ie.tsinghua.edu.cn/eng/), [Tsinghua University](https://www.tsinghua.edu.cn/en/) in 2020. 

During most of my PhD years, I had the opportunity to intern at the  [International Digital Economy Academy (IDEA)](https://idea.edu.cn/), under the supervision of [Prof. Lei Zhang](https://www.leizhang.org/). I was an intern at NVIDIA and Microsoft Research, where I was fortunate to collaborate with talented researchers including [Guilin Liu](https://liuguilin1225.github.io/), [Zhiding Yu](https://chrisding.github.io/), [Chunyuan Li](https://chunyuan.li/), [Hao Cheng](https://sites.google.com/site/hcheng2site), and [Jianwei Yang](https://jwyang.github.io/).

My previous work focused on computer vision, particularly object detection, and multi-modal learning. Here are some of my representative works:

- Detection Transformers: We proposed a series of improvements on Detection Transformer including [DAB-DETR](https://github.com/IDEA-Research/DAB-DETR)<img src="https://img.shields.io/github/stars/IDEA-Research/DAB-DETR" alt="GitHub stars">, [DN-DETR](https://github.com/IDEA-Research/DN-DETR)<img src="https://img.shields.io/github/stars/IDEA-Research/DN-DETR" alt="GitHub stars">, [DINO](https://github.com/IDEA-Research/DINO)<img src="https://img.shields.io/github/stars/IDEA-Research/DINO" alt="GitHub stars">, [MaskDINO](https://github.com/IDEA-Research/MaskDINO)<img src="https://img.shields.io/github/stars/IDEA-Research/MaskDINO" alt="GitHub stars">, and [Stable-DINO](https://github.com/IDEA-Research/Stable-DINO)<img src="https://img.shields.io/github/stars/IDEA-Research/Stable-DINO" alt="GitHub stars">. Notably, [DINO](https://github.com/IDEA-Research/DINO) was the **FIRST** DETR-like model to achieve state-of-the-art performance on the COCO object detection leaderboard.

- Open-world Object Detection: Our innovative models [Grounding DINO](https://github.com/IDEA-Research/GroundingDINO)<img src="https://img.shields.io/github/stars/IDEA-Research/GroundingDINO" alt="GitHub stars">, [Grounded-SAM](https://github.com/IDEA-Research/Grounded-Segment-Anything)<img src="https://img.shields.io/github/stars/IDEA-Research/Grounded-Segment-Anything" alt="GitHub stars">, and [Grounding-DINO-1.5](https://deepdataspace.com/) have made significant strides in this field. Grounding DINO has become one of the most popular open-world object detection models, enabling us to DETECT and SEGMENT ANYTHING.

- Multi-modal Agents: We introduced [LLaVA-Plus](https://github.com/LLaVA-VL/LLaVA-Plus-Codebase), which enhances multi-modal large language models with visual expertise. 


<div class="summary" style="font-weight: bold; font-size: larger;">
  I expect to graduate at June 2025. I am opening to both academic positions and industrial research positions. <a href="https://drive.google.com/file/d/1oxb-vADJiA-spvOXSK-l66AwmGOK1Stc/view?usp=sharing" rel="external nofollow noopener" target="_blank">Download my CV.</a>
</div>

Contact me with my email: slongliu86 AT gmail.com or liusl20 AT mails.tsinghua.edu.cn 

Feel free to add me on WeChat (SLONG_88) if you'd like. Please include a brief note about yourself when sending the request.

[Google Scholar](https://scholar.google.com/citations?user=nkSVY3MAAAAJ&hl=en) | [GitHub](https://github.com/SlongLiu) | [Twitter](https://twitter.com/atasteoff) | [Zhihu 知乎](https://www.zhihu.com/people/3089892) | [CV](https://drive.google.com/file/d/1oxb-vADJiA-spvOXSK-l66AwmGOK1Stc/view?usp=sharing) 


